{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b6725-b61f-4534-a2f0-89a967c1c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import random\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import pickle\n",
    "import scipy\n",
    "import sklearn\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8845e8c1-3f28-4f73-aa41-847ef54dcc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "#### DATA #######\n",
    "#################\n",
    "\n",
    "\n",
    "df = pd.read_csv('full_2020_bow.csv') ## Full data available on request\n",
    "\n",
    "\n",
    "# Chronological sorting of articles\n",
    "df['date'] = pd.to_datetime(df['article_time'])\n",
    "df = df.sort_values(by='date')\n",
    "\n",
    "import random\n",
    "random.seed(1234)\n",
    "article_ids = np.array(df.article_id)\n",
    "articles = np.unique(article_ids)\n",
    "\n",
    "# Splitting at the halfway point\n",
    "set1 = articles[:1476]\n",
    "set2 = articles[1477:]\n",
    "\n",
    "\n",
    "\n",
    "# Getting row indices for each set of articles in original data\n",
    "index1 = []\n",
    "index2 = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    if row.article_id in set1:\n",
    "        index1.append(row.Index)\n",
    "    else:\n",
    "        index2.append(row.Index)\n",
    "        \n",
    "df1 = df.loc[index1,:] #### DATASET 1: for train, val, test\n",
    "df2 = df.loc[index2,:] #### DATASET 2: for unseen eval articles\n",
    "\n",
    "\n",
    "## Tokenizer for biLSTM and CNN\n",
    "max_words = 10000  \n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "all_texts = list(df.content)\n",
    "tokenizer.fit_on_texts(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9440f3d-d861-4c90-8674-14c35df67056",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "## MODEL #\n",
    "##########\n",
    "\n",
    "with open('', 'rb') as f: ## fill in model\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3838477-e7bf-4b0c-b399-5508c0be16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "### RANKING #########\n",
    "#####################\n",
    "\n",
    "# This notebook contains different cells for ranking depending on the variable set used by the model\n",
    "# First cell runs code to rank based on models not trained on textual data: RF, SVM(correct_cols excludes BoW features)\n",
    "# Second cell runs code to rank Rf_BoW, it keeps BoW columns (correct_cols to make sure feature set matches the trained model)\n",
    "# third cell runs baseline\n",
    "# fourth cell runs CNN and biLSTM\n",
    "# fifth RobBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd07ebd-7bdc-4c94-b2d7-90a632f68e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF, SVM\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import collections\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import glob\n",
    "import math\n",
    "import argparse \n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n",
    "at_3 = []\n",
    "at_5 = []\n",
    "at_10 = []\n",
    "\n",
    "prec_5 = []\n",
    "\n",
    "correct_cols = [\n",
    " 'reply_count',\n",
    " 'respect_count',\n",
    " #'featured',\n",
    " 'delta_minutes',\n",
    " 'featured_posts_user',\n",
    " 'rejected_count_user',\n",
    " 'total_respect_user',\n",
    " 'total_posts_user',\n",
    " 'total_received_responses_user',\n",
    " 'ratio_rejected',\n",
    " 'ratio_featured',\n",
    " 'ratio_reply',\n",
    " 'ratio_respect',\n",
    " 'wordcount',\n",
    " 'intro_dist',\n",
    " 'centr_dist',\n",
    " 'avg_wordcount_user'\n",
    "]\n",
    "\n",
    "articles = list(set(df2.article_id))\n",
    "\n",
    "for art in articles:\n",
    "    nf = []\n",
    "    f = []\n",
    "    df_now = df2[df2.article_id==art]\n",
    "    \n",
    "    labels = df_now.featured\n",
    "    content = df_now.content\n",
    "    labels = list(labels)\n",
    "    df_now = df_now[df_now.columns.intersection(correct_cols)]\n",
    "    df_now = df_now.fillna(0)\n",
    "    \n",
    "    pred = model.predict_proba(df_now)\n",
    "    pred = pd.DataFrame(pred)\n",
    "    f = []\n",
    "    nf = []\n",
    "    pred.rename({0: 'nf', 1: 'f'}, axis=1, inplace=True)\n",
    "    for row in pred.itertuples():\n",
    "        if row.nf>0.5:\n",
    "            nf.append(1)\n",
    "            f.append(0)\n",
    "        else:\n",
    "            nf.append(0)\n",
    "            f.append(1)\n",
    "    labels2 = []\n",
    "    for lab in labels:\n",
    "        if lab == True:\n",
    "            labels2.append(1)\n",
    "        else:\n",
    "            labels2.append(0)\n",
    "    pred['pred_label']= f\n",
    "    pred['label'] = labels2\n",
    "    if 1 not in f:\n",
    "        continue\n",
    "    if 1 not in labels2:\n",
    "        continue        \n",
    "    pred = pred.sort_values(by=['f'], ascending=False)\n",
    "\n",
    "    pred2 = list(pred['pred_label'])\n",
    "    true2 = pred['label']\n",
    "    labs = list(pred['label'])\n",
    "    if len(labs)<10:\n",
    "        continue\n",
    "    for k in [3,5,10]:\n",
    "        labs2 = labs[:k]\n",
    "        preds2_temp = pred2[:k]\n",
    "        if k == 3:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))\n",
    "            if idcg ==0:\n",
    "                at_3.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_3.append(ndcg)\n",
    "        if k ==5:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))+(labs[3]/np.log2(4+1))+(labs[4]/np.log2(5+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))+(sorte[3]/np.log2(4+1))+(sorte[4]/np.log2(5+1))\n",
    "            if idcg ==0:\n",
    "                at_5.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_5.append(ndcg)\n",
    "            prec_5.append(precision_score(labs2, preds2_temp, pos_label=1))\n",
    "\n",
    "        if k ==10:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))+(labs[3]/np.log2(4+1))+(labs[4]/np.log2(5+1))+(labs[5]/np.log2(6+1))+(labs[6]/np.log2(7+1))+(labs[7]/np.log2(8+1))+(labs[8]/np.log2(9+1))+(labs[9]/np.log2(10+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))+(sorte[3]/np.log2(4+1))+(sorte[4]/np.log2(5+1))+(sorte[5]/np.log2(6+1))+(sorte[6]/np.log2(7+1))+(sorte[7]/np.log2(8+1))+(sorte[8]/np.log2(9+1))+(sorte[9]/np.log2(10+1))\n",
    "            if idcg ==0:\n",
    "                at_10.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_10.append(ndcg)\n",
    "    \n",
    "print('at3', s.mean(at_3),'at5', s.mean(at_5),'at10',s.mean(at_10))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820bb03-e288-46db-a15d-4938ecb1283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_cols = [\n",
    " 'reply_count',\n",
    " 'respect_count',\n",
    " 'featured',\n",
    " 'delta_minutes',\n",
    " 'featured_posts_user',\n",
    " 'rejected_count_user',\n",
    " 'total_respect_user',\n",
    " 'total_posts_user',\n",
    " 'total_received_responses_user',\n",
    " 'ratio_rejected',\n",
    " 'ratio_featured',\n",
    " 'ratio_reply',\n",
    " 'ratio_respect',\n",
    " 'wordcount',\n",
    " 'intro_dist',\n",
    " 'centr_dist',\n",
    " 'avg_wordcount_user',\n",
    "    '000',\n",
    " '10',\n",
    " '100',\n",
    " '20',\n",
    " 'aan het',\n",
    " 'aan te',\n",
    " 'aantal',\n",
    " 'achter',\n",
    " 'acties',\n",
    " 'af',\n",
    " 'afgelopen',\n",
    " 'afstand',\n",
    " 'al die',\n",
    " 'alleen maar',\n",
    " 'allemaal',\n",
    " 'alles',\n",
    " 'als de',\n",
    " 'als een',\n",
    " 'als er',\n",
    " 'als het',\n",
    " 'als ik',\n",
    " 'als je',\n",
    " 'als we',\n",
    " 'als ze',\n",
    " 'altijd',\n",
    " 'ander',\n",
    " 'anderen',\n",
    " 'anders',\n",
    " 'artikel',\n",
    " 'auto',\n",
    " 'bedrijf',\n",
    " 'bedrijven',\n",
    " 'beetje',\n",
    " 'beleid',\n",
    " 'bent',\n",
    " 'besmet',\n",
    " 'besmettingen',\n",
    " 'best',\n",
    " 'beste',\n",
    " 'betalen',\n",
    " 'beter',\n",
    " 'betreft',\n",
    " 'bevolking',\n",
    " 'bezig',\n",
    " 'bij de',\n",
    " 'bijna',\n",
    " 'bijvoorbeeld',\n",
    " 'binnen',\n",
    " 'blijft',\n",
    " 'blijkbaar',\n",
    " 'blijven',\n",
    " 'boer',\n",
    " 'br br',\n",
    " 'br de',\n",
    " 'br div',\n",
    " 'br div div',\n",
    " 'buiten',\n",
    " 'burgers',\n",
    " 'china',\n",
    " 'cijfers',\n",
    " 'corona',\n",
    " 'covid',\n",
    " 'daarnaast',\n",
    " 'daarom',\n",
    " 'dag',\n",
    " 'dagen',\n",
    " 'dan de',\n",
    " 'dan is',\n",
    " 'dan ook',\n",
    " 'dat dit',\n",
    " 'dat een',\n",
    " 'dat er',\n",
    " 'dat hij',\n",
    " 'dat ik',\n",
    " 'dat je',\n",
    " 'dat niet',\n",
    " 'dat we',\n",
    " 'dat ze',\n",
    " 'de maatregelen',\n",
    " 'de meeste',\n",
    " 'de mensen',\n",
    " 'de natuur',\n",
    " 'de overheid',\n",
    " 'de politie',\n",
    " 'de regels',\n",
    " 'de regering',\n",
    " 'de rest',\n",
    " 'de wereld',\n",
    " 'de zorg',\n",
    " 'deel',\n",
    " 'denk',\n",
    " 'denk dat',\n",
    " 'denken',\n",
    " 'denkt',\n",
    " 'dicht',\n",
    " 'die de',\n",
    " 'die het',\n",
    " 'dingen',\n",
    " 'dit is',\n",
    " 'dit soort',\n",
    " 'div br',\n",
    " 'div br div',\n",
    " 'div div',\n",
    " 'div div br',\n",
    " 'doden',\n",
    " 'doe',\n",
    " 'doet',\n",
    " 'door de',\n",
    " 'druk',\n",
    " 'duidelijk',\n",
    " 'duitsland',\n",
    " 'echter',\n",
    " 'economie',\n",
    " 'een beetje',\n",
    " 'een paar',\n",
    " 'eerder',\n",
    " 'eerst',\n",
    " 'eerste',\n",
    " 'eigen',\n",
    " 'eigenlijk',\n",
    " 'elkaar',\n",
    " 'elke',\n",
    " 'en als',\n",
    " 'en dan',\n",
    " 'en dat',\n",
    " 'en die',\n",
    " 'en een',\n",
    " 'en het',\n",
    " 'en ik',\n",
    " 'en niet',\n",
    " 'enige',\n",
    " 'enkel',\n",
    " 'enkele',\n",
    " 'er een',\n",
    " 'er geen',\n",
    " 'er is',\n",
    " 'er niet',\n",
    " 'er nog',\n",
    " 'er ook',\n",
    " 'er zijn',\n",
    " 'erg',\n",
    " 'etc',\n",
    " 'eten',\n",
    " 'eu',\n",
    " 'europa',\n",
    " 'even',\n",
    " 'extra',\n",
    " 'feit',\n",
    " 'ga',\n",
    " 'gebeuren',\n",
    " 'gebruiken',\n",
    " 'gedaan',\n",
    " 'gedrag',\n",
    " 'geeft',\n",
    " 'gehad',\n",
    " 'geld',\n",
    " 'geleden',\n",
    " 'gelijk',\n",
    " 'gelukkig',\n",
    " 'gemaakt',\n",
    " 'genoeg',\n",
    " 'geval',\n",
    " 'geven',\n",
    " 'geweest',\n",
    " 'gezegd',\n",
    " 'gezien',\n",
    " 'goede',\n",
    " 'graag',\n",
    " 'griep',\n",
    " 'groep',\n",
    " 'grond',\n",
    " 'groot',\n",
    " 'grootste',\n",
    " 'grote',\n",
    " 'haar',\n",
    " 'had',\n",
    " 'hadden',\n",
    " 'halen',\n",
    " 'hand',\n",
    " 'hard',\n",
    " 'heb ik',\n",
    " 'heb je',\n",
    " 'hebben we',\n",
    " 'hebt',\n",
    " 'heel veel',\n",
    " 'helaas',\n",
    " 'hele',\n",
    " 'helemaal',\n",
    " 'helemaal niet',\n",
    " 'helpen',\n",
    " 'hem',\n",
    " 'het aantal',\n",
    " 'het een',\n",
    " 'het gaat',\n",
    " 'het kabinet',\n",
    " 'het land',\n",
    " 'het niet',\n",
    " 'het ook',\n",
    " 'het probleem',\n",
    " 'het rivm',\n",
    " 'het virus',\n",
    " 'het wel',\n",
    " 'hij',\n",
    " 'hoeveel',\n",
    " 'hoop',\n",
    " 'hoor',\n",
    " 'houden',\n",
    " 'huis',\n",
    " 'ic',\n",
    " 'idee',\n",
    " 'ieder',\n",
    " 'iedereen',\n",
    " 'iemand',\n",
    " 'iets',\n",
    " 'ik ben',\n",
    " 'ik denk',\n",
    " 'ik denk dat',\n",
    " 'ik heb',\n",
    " 'ik het',\n",
    " 'ik vind',\n",
    " 'in een',\n",
    " 'in het',\n",
    " 'in nederland',\n",
    " 'inderdaad',\n",
    " 'is dan',\n",
    " 'is dat',\n",
    " 'is de',\n",
    " 'is een',\n",
    " 'is en',\n",
    " 'is er',\n",
    " 'is geen',\n",
    " 'is niet',\n",
    " 'is ook',\n",
    " 'is voor',\n",
    " 'ja',\n",
    " 'jaar',\n",
    " 'jaren',\n",
    " 'je dat',\n",
    " 'je de',\n",
    " 'je een',\n",
    " 'je het',\n",
    " 'je niet',\n",
    " 'jij',\n",
    " 'juist',\n",
    " 'jullie',\n",
    " 'kabinet',\n",
    " 'kan je',\n",
    " 'kans',\n",
    " 'kant',\n",
    " 'keer',\n",
    " 'kijk',\n",
    " 'kijken',\n",
    " 'kinderen',\n",
    " 'kleine',\n",
    " 'klopt',\n",
    " 'kom',\n",
    " 'komt',\n",
    " 'krijgen',\n",
    " 'krijgt',\n",
    " 'kun',\n",
    " 'kun je',\n",
    " 'kunt',\n",
    " 'laat',\n",
    " 'laatste',\n",
    " 'land',\n",
    " 'landen',\n",
    " 'lang',\n",
    " 'laten',\n",
    " 'laten we',\n",
    " 'lees',\n",
    " 'lekker',\n",
    " 'leven',\n",
    " 'liggen',\n",
    " 'ligt',\n",
    " 'lijkt',\n",
    " 'lockdown',\n",
    " 'lopen',\n",
    " 'maakt',\n",
    " 'maanden',\n",
    " 'maar dat',\n",
    " 'maar de',\n",
    " 'maar een',\n",
    " 'maar het',\n",
    " 'maar ik',\n",
    " 'maatregelen',\n",
    " 'mag',\n",
    " 'maken',\n",
    " 'man',\n",
    " 'manier',\n",
    " 'me',\n",
    " 'media',\n",
    " 'meer dan',\n",
    " 'meeste',\n",
    " 'men',\n",
    " 'mening',\n",
    " 'mensen die',\n",
    " 'met de',\n",
    " 'met een',\n",
    " 'met het',\n",
    " 'meter',\n",
    " 'mijn',\n",
    " 'miljoen',\n",
    " 'minder',\n",
    " 'misschien',\n",
    " 'moet je',\n",
    " 'mogelijk',\n",
    " 'mogen',\n",
    " 'moment',\n",
    " 'mondkapje',\n",
    " 'mondkapjes',\n",
    " 'mooi',\n",
    " 'na',\n",
    " 'naar de',\n",
    " 'naar het',\n",
    " 'namelijk',\n",
    " 'natuur',\n",
    " 'natuurlijk',\n",
    " 'nederlandse',\n",
    " 'nee',\n",
    " 'nemen',\n",
    " 'net',\n",
    " 'net als',\n",
    " 'niemand',\n",
    " 'niet aan',\n",
    " 'niet alleen',\n",
    " 'niet dat',\n",
    " 'niet de',\n",
    " 'niet eens',\n",
    " 'niet in',\n",
    " 'niet meer',\n",
    " 'niet op',\n",
    " 'niet te',\n",
    " 'niet voor',\n",
    " 'niet zo',\n",
    " 'niets',\n",
    " 'nieuwe',\n",
    " 'nieuws',\n",
    " 'niks',\n",
    " 'nl',\n",
    " 'nodig',\n",
    " 'nog een',\n",
    " 'nog niet',\n",
    " 'nog steeds',\n",
    " 'nooit',\n",
    " 'normaal',\n",
    " 'nou',\n",
    " 'om de',\n",
    " 'om een',\n",
    " 'om het',\n",
    " 'om te',\n",
    " 'onder',\n",
    " 'onderzoek',\n",
    " 'ons',\n",
    " 'onze',\n",
    " 'onzin',\n",
    " 'ook de',\n",
    " 'ook een',\n",
    " 'ook niet',\n",
    " 'ook nog',\n",
    " 'op een',\n",
    " 'op het',\n",
    " 'op te',\n",
    " 'open',\n",
    " 'oplossing',\n",
    " 'over de',\n",
    " 'overheid',\n",
    " 'paar',\n",
    " 'partijen',\n",
    " 'pas',\n",
    " 'per',\n",
    " 'plaats',\n",
    " 'politie',\n",
    " 'politiek',\n",
    " 'praten',\n",
    " 'precies',\n",
    " 'prima',\n",
    " 'probleem',\n",
    " 'problemen',\n",
    " 'reactie',\n",
    " 'reden',\n",
    " 'regels',\n",
    " 'regering',\n",
    " 'rest',\n",
    " 'risico',\n",
    " 'rivm',\n",
    " 'rusland',\n",
    " 'rutte',\n",
    " 'scholen',\n",
    " 'situatie',\n",
    " 'snap',\n",
    " 'snel',\n",
    " 'soort',\n",
    " 'staan',\n",
    " 'staat',\n",
    " 'steeds',\n",
    " 'stemmen',\n",
    " 'stikstof',\n",
    " 'stoppen',\n",
    " 'straks',\n",
    " 'te doen',\n",
    " 'te gaan',\n",
    " 'te houden',\n",
    " 'te maken',\n",
    " 'te zijn',\n",
    " 'tegen',\n",
    " 'ten',\n",
    " 'terug',\n",
    " 'terwijl',\n",
    " 'testen',\n",
    " 'thuis',\n",
    " 'tijd',\n",
    " 'toe',\n",
    " 'toen',\n",
    " 'totaal',\n",
    " 'trump',\n",
    " 'tussen',\n",
    " 'twee',\n",
    " 'uit de',\n",
    " 'uitstoot',\n",
    " 'uw',\n",
    " 'vaak',\n",
    " 'vaccin',\n",
    " 'valt',\n",
    " 'van deze',\n",
    " 'van een',\n",
    " 'van het',\n",
    " 'vanaf',\n",
    " 'vanuit',\n",
    " 'vast',\n",
    " 'veel mensen',\n",
    " 'vele',\n",
    " 'verder',\n",
    " 'vind',\n",
    " 'vinden',\n",
    " 'virus',\n",
    " 'vlees',\n",
    " 'vol',\n",
    " 'volgens',\n",
    " 'volgens mij',\n",
    " 'voor een',\n",
    " 'voor het',\n",
    " 'vooral',\n",
    " 'vraag',\n",
    " 'waarom',\n",
    " 'waarschijnlijk',\n",
    " 'wanneer',\n",
    " 'want',\n",
    " 'waren',\n",
    " 'wat een',\n",
    " 'wat er',\n",
    " 'week',\n",
    " 'weet',\n",
    " 'weg',\n",
    " 'weinig',\n",
    " 'weken',\n",
    " 'wel een',\n",
    " 'welke',\n",
    " 'werd',\n",
    " 'wereld',\n",
    " 'werk',\n",
    " 'werken',\n",
    " 'werkt',\n",
    " 'wet',\n",
    " 'weten',\n",
    " 'wie',\n",
    " 'wij',\n",
    " 'wil',\n",
    " 'willen',\n",
    " 'wilt',\n",
    " 'word',\n",
    " 'zaken',\n",
    " 'zal',\n",
    " 'ze niet',\n",
    " 'zeer',\n",
    " 'zeg',\n",
    " 'zeggen',\n",
    " 'zegt',\n",
    " 'zeker',\n",
    " 'zelfs',\n",
    " 'zetten',\n",
    " 'zie',\n",
    " 'ziek',\n",
    " 'ziekenhuis',\n",
    " 'zien',\n",
    " 'ziet',\n",
    " 'zij',\n",
    " 'zijn de',\n",
    " 'zijn en',\n",
    " 'zijn er',\n",
    " 'zin',\n",
    " 'zit',\n",
    " 'zitten',\n",
    " 'zoals',\n",
    " 'zodat',\n",
    " 'zonder',\n",
    " 'zorg',\n",
    " 'zorgen',\n",
    " 'zouden',\n",
    " 'zoveel',\n",
    " 'zullen'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a96f1-73b8-44a7-87bb-7b900d2b1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RF_BoW\n",
    "\n",
    "import statistics as s\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import collections\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import glob\n",
    "import math\n",
    "import argparse \n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "at_3 = []\n",
    "at_5 = []\n",
    "at_10 = []\n",
    "\n",
    "prec_5 = []\n",
    "prec_3 = []\n",
    "\n",
    "\n",
    "articles = list(set(df2.article_id))\n",
    "\n",
    "for art in articles:\n",
    "    nf = []\n",
    "    f = []\n",
    "    df_now = df2[df2.article_id==art]\n",
    "    \n",
    "    labels = df_now.featured\n",
    "    content = df_now.content\n",
    "    topics = list(set(list(df_now.preferred_section_id)))\n",
    "    labels = list(labels)\n",
    "    df_now = df_now[df_now.columns.intersection(correct_cols)]\n",
    "    df_now = df_now.fillna(0)\n",
    "    \n",
    "    pred = model.predict_proba(df_now)\n",
    "    pred = pd.DataFrame(pred)\n",
    "    f = []\n",
    "    nf = []\n",
    "    pred.rename({0: 'nf', 1: 'f'}, axis=1, inplace=True)\n",
    "    for row in pred.itertuples():\n",
    "        if row.nf>0.5:\n",
    "            nf.append(1)\n",
    "            f.append(0)\n",
    "        else:\n",
    "            nf.append(0)\n",
    "            f.append(1)\n",
    "    labels2 = []\n",
    "    for lab in labels:\n",
    "        if lab == True:\n",
    "            labels2.append(1)\n",
    "        else:\n",
    "            labels2.append(0)\n",
    "    pred['pred_label']= f\n",
    "    pred['label'] = labels2\n",
    "    if 1 not in f:\n",
    "        continue\n",
    "    if 1 not in labels2:\n",
    "        continue        \n",
    "    pred = pred.sort_values(by=['f'], ascending=False)\n",
    "\n",
    "    pred2 = pred['pred_label']\n",
    "    true2 = pred['label']\n",
    "    labs = list(pred['label'])\n",
    "    if len(labs)<10:\n",
    "        continue\n",
    "    if 1778528 in topics:\n",
    "        topic.append('Covid-19')\n",
    "    elif 1380734 in topics:\n",
    "        topic.append('US election 2020')\n",
    "    else:\n",
    "        topic.append('Climate change')\n",
    "    for k in [3,5,10]:\n",
    "        labs2 = labs[:k]\n",
    "        if k == 3:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))\n",
    "            if idcg ==0:\n",
    "                at_3.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_3.append(ndcg)\n",
    "            prec_3.append(precision_score(labs2, preds2_temp, pos_label=1))\n",
    "            \n",
    "        if k ==5:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))+(labs[3]/np.log2(4+1))+(labs[4]/np.log2(5+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))+(sorte[3]/np.log2(4+1))+(sorte[4]/np.log2(5+1))\n",
    "            if idcg ==0:\n",
    "                at_5.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_5.append(ndcg)\n",
    "            prec_5.append(precision_score(labs2, preds2_temp, pos_label=1))\n",
    "        if k ==10:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))+(labs[3]/np.log2(4+1))+(labs[4]/np.log2(5+1))+(labs[5]/np.log2(6+1))+(labs[6]/np.log2(7+1))+(labs[7]/np.log2(8+1))+(labs[8]/np.log2(9+1))+(labs[9]/np.log2(10+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))+(sorte[3]/np.log2(4+1))+(sorte[4]/np.log2(5+1))+(sorte[5]/np.log2(6+1))+(sorte[6]/np.log2(7+1))+(sorte[7]/np.log2(8+1))+(sorte[8]/np.log2(9+1))+(sorte[9]/np.log2(10+1))\n",
    "            if idcg ==0:\n",
    "                at_10.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_10.append(ndcg)\n",
    "    \n",
    "print('at3', s.mean(at_3),'at5', s.mean(at_5),'at10',s.mean(at_10))    \n",
    "print('Precision scores @: at3', s.mean(prec_3), 'at5', s.mean(prec_5))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb67b8b-6f4f-4458-b3c8-f4458942ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BASELINE \n",
    "\n",
    "import statistics as s\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import collections\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import glob\n",
    "import math\n",
    "import argparse \n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "at_3 = []\n",
    "at_5 = []\n",
    "at_10 = []\n",
    "prec_5 = []\n",
    "prec_3 = []\n",
    "\n",
    "articles = list(set(df2.article_id))\n",
    "\n",
    "for art in articles:\n",
    "    nf = []\n",
    "    f = []\n",
    "    df_now = df2[df2.article_id==art]\n",
    "    \n",
    "    labels = df_now.featured\n",
    "    labels = list(labels)\n",
    "    df_now = df_now[df_now.columns.intersection(correct_cols)]\n",
    "    df_now = df_now[order]\n",
    "    df_now = df_now.fillna(0)\n",
    "    rfeat = list(df_now.ratio_featured)\n",
    "    f = []\n",
    "    nf = []\n",
    "    pred.rename({0: 'nf', 1: 'f'}, axis=1, inplace=True)\n",
    "    for i in range(len(rfeat)):\n",
    "        if rfeat[i]>0.03:\n",
    "            nf.append(1)\n",
    "            f.append(0)\n",
    "        else:\n",
    "            nf.append(0)\n",
    "            f.append(1)\n",
    "    labels2 = []\n",
    "    for lab in labels:\n",
    "        if lab == True:\n",
    "            labels2.append(1)\n",
    "        else:\n",
    "            labels2.append(0)\n",
    "    pred = pd.DataFrame(rfeat)\n",
    "    pred['pred_label']=nf\n",
    "    pred['label'] = labels2\n",
    "    if 1 not in f:\n",
    "        continue\n",
    "    if 1 not in labels2:\n",
    "        continue        \n",
    "    pred = pred.sort_values(by=[0], ascending=False)\n",
    "\n",
    "    pred2 = pred['pred_label']\n",
    "    true2 = pred['label']\n",
    "    labs = list(pred['label'])\n",
    "    if len(labs)<10:\n",
    "        continue\n",
    "    for k in [3,5,10]:\n",
    "        labs2 = labs[:k]\n",
    "        if k == 3:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))\n",
    "            if idcg ==0:\n",
    "                at_3.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_3.append(ndcg)\n",
    "            prec_3.append(precision_score(labs2, preds2_temp, pos_label=1))\n",
    "\n",
    "        if k ==5:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))+(labs[3]/np.log2(4+1))+(labs[4]/np.log2(5+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))+(sorte[3]/np.log2(4+1))+(sorte[4]/np.log2(5+1))\n",
    "            if idcg ==0:\n",
    "                at_5.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_5.append(ndcg)\n",
    "            prec_5.append(precision_score(labs2, preds2_temp, pos_label=1))\n",
    "\n",
    "        if k ==10:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))+(labs[3]/np.log2(4+1))+(labs[4]/np.log2(5+1))+(labs[5]/np.log2(6+1))+(labs[6]/np.log2(7+1))+(labs[7]/np.log2(8+1))+(labs[8]/np.log2(9+1))+(labs[9]/np.log2(10+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))+(sorte[3]/np.log2(4+1))+(sorte[4]/np.log2(5+1))+(sorte[5]/np.log2(6+1))+(sorte[6]/np.log2(7+1))+(sorte[7]/np.log2(8+1))+(sorte[8]/np.log2(9+1))+(sorte[9]/np.log2(10+1))\n",
    "            if idcg ==0:\n",
    "                at_10.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_10.append(ndcg)\n",
    "    \n",
    "print('at3', s.mean(at_3),'at5', s.mean(at_5),'at10',s.mean(at_10))    \n",
    "print('Precision scores @: at3', s.mean(prec_3), 'at5', s.mean(prec_5))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56472d4c-dd5a-445a-8db7-6255b377052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN or biLSTM\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import collections\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import glob\n",
    "import math\n",
    "import argparse \n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "import statistics as s\n",
    "\n",
    "at_3 = []\n",
    "at_5 = []\n",
    "at_10 = []\n",
    "\n",
    "prec_5 = []\n",
    "prec_3 = []\n",
    "\n",
    "\n",
    "articles = list(set(df2.article_id))\n",
    "\n",
    "for art in articles:\n",
    "    nf = []\n",
    "    f = []\n",
    "    df_now = df2[df2.article_id==art]\n",
    "    \n",
    "    labels = df_now.featured\n",
    "    content = list(df_now.content)\n",
    "    labels = list(labels)\n",
    "\n",
    "    art_seq = tokenizer.texts_to_sequences(content)\n",
    "    max_sequence_length = 100  \n",
    "    padded_sequences_art = pad_sequences(art_seq, maxlen=max_sequence_length)\n",
    "\n",
    "    predictions = model.predict(padded_sequences_art)\n",
    "    preds = []\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i]>0.5:\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "    \n",
    "    labels2 = []\n",
    "    for lab in labels:\n",
    "        if lab == True:\n",
    "            labels2.append(1)\n",
    "        else:\n",
    "            labels2.append(0)\n",
    "\n",
    "    \n",
    "\n",
    "    if 1 not in preds:\n",
    "        print('none pred')\n",
    "        continue\n",
    "    if 1 not in labels2:\n",
    "        print('none real')\n",
    "        continue      \n",
    "        \n",
    "    pred = pd.DataFrame(predictions)\n",
    "    pred.columns=['feat']\n",
    "    pred['non_feat'] = 1- pred.feat\n",
    "    pred['pred_label'] = preds\n",
    "    pred['label'] = labels2\n",
    "    pred = pred.sort_values(by=['feat'], ascending=False)\n",
    "\n",
    "    pred2 = list(pred['pred_label'])\n",
    "   \n",
    "    true2 = pred['label']\n",
    "    labs = list(pred['label'])\n",
    "    if len(labs)<10:\n",
    "        continue\n",
    "    for k in [3,5,10]:\n",
    "        labs2 = labs[:k]\n",
    "        preds2_temp = pred2[:k]\n",
    "        if k == 3:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))\n",
    "            if idcg ==0:\n",
    "                at_3.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_3.append(ndcg)\n",
    "            prec_3.append(precision_score(labs2, preds2_temp, pos_label=1))\n",
    "        if k ==5:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))+(labs[3]/np.log2(4+1))+(labs[4]/np.log2(5+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))+(sorte[3]/np.log2(4+1))+(sorte[4]/np.log2(5+1))\n",
    "            if idcg ==0:\n",
    "                at_5.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_5.append(ndcg)\n",
    "            prec_5.append(precision_score(labs2, preds2_temp, pos_label=1))\n",
    "\n",
    "        if k ==10:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))+(labs[3]/np.log2(4+1))+(labs[4]/np.log2(5+1))+(labs[5]/np.log2(6+1))+(labs[6]/np.log2(7+1))+(labs[7]/np.log2(8+1))+(labs[8]/np.log2(9+1))+(labs[9]/np.log2(10+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))+(sorte[3]/np.log2(4+1))+(sorte[4]/np.log2(5+1))+(sorte[5]/np.log2(6+1))+(sorte[6]/np.log2(7+1))+(sorte[7]/np.log2(8+1))+(sorte[8]/np.log2(9+1))+(sorte[9]/np.log2(10+1))\n",
    "            if idcg ==0:\n",
    "                at_10.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_10.append(ndcg)\n",
    "    \n",
    "print('NDCG scores: at3', s.mean(at_3),'at5', s.mean(at_5),'at10',s.mean(at_10))   \n",
    "print('Precision scores @: at3', s.mean(prec_3), 'at5', s.mean(prec_5))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f764c0f-7a04-485e-abc1-deb9eb98392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RobBERT\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import collections\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import glob\n",
    "import math\n",
    "import argparse \n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, BertTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robBERT-base\")\n",
    "at_3 = []\n",
    "at_5= []\n",
    "at_10=[]\n",
    "prec_3 = []\n",
    "prec_5 = []\n",
    "\n",
    "target_names = ['Not_feat', 'Feat']\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"\",num_labels=len(target_names)) ## select model\n",
    "\n",
    "\n",
    "def get_prediction(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=205, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs[0].softmax(1)\n",
    "    return probs.tolist()\n",
    "\n",
    "\n",
    "\n",
    "used_arts = []\n",
    "articles = list(set(df2.article_id))\n",
    "\n",
    "for art in articles:\n",
    "    if art in used_arts:\n",
    "        print('already done')\n",
    "        continue\n",
    "    \n",
    "    nf = []\n",
    "    f = []\n",
    "    df_now = df2[df2.article_id==art]\n",
    "    df_feat = df_now[df_now.featured==True]\n",
    "\n",
    "    text = list(df_now.content)\n",
    "    labels = df_now.featured\n",
    "\n",
    "    for x in range(len(labels)):\n",
    "        if labels[x]==False:\n",
    "            labels[x]='Not_feat'\n",
    "        else:\n",
    "            labels[x]='Feat'\n",
    "    #print('Got the labels')\n",
    "    for p in range(len(text)):\n",
    "        temp = get_prediction(text[p])\n",
    "        temp = temp[0]\n",
    "        nf.append(temp[0])\n",
    "        f.append(temp[1])\n",
    "        #print(p)\n",
    "    pred = pd.DataFrame(nf)\n",
    "    pred['featured'] = f\n",
    "    pred = pred.rename(columns={0: 'Not_featured', 'featured': 'Featured'})\n",
    "    pred_label = []\n",
    "    for row in pred.itertuples():\n",
    "        if row.Not_featured  > row.Featured:\n",
    "            pred_label.append('Not_Featured')\n",
    "        else:\n",
    "            pred_label.append('Featured')\n",
    "        \n",
    "    pred['Pred_label'] = pred_label\n",
    "    pred['Label'] = labels\n",
    "    pred = pred.sort_values(by=['Featured'], ascending=False)\n",
    "\n",
    "    if 'Featured' not in pred_label:\n",
    "        continue\n",
    "    if 'Feat' not in labels:\n",
    "        continue\n",
    "    pred = pred.sort_values(by=['Featured'], ascending=False)\n",
    "    pred2 = []\n",
    "    true2 = []\n",
    "    for row in pred.itertuples():\n",
    "        if row.Pred_label=='Featured':\n",
    "            pred2.append(1)\n",
    "        else:\n",
    "            pred2.append(0)\n",
    "        if row.Label=='Feat':\n",
    "            true2.append(1)\n",
    "        else:\n",
    "            true2.append(0)\n",
    "\n",
    "    labs = true2\n",
    "    if len(pred)<10:\n",
    "        continue\n",
    "    for k in [3,5,10]:\n",
    "        labs2 = labs[:k]\n",
    "        if k == 3:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))\n",
    "            if idcg ==0:\n",
    "                at_3.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_3.append(ndcg)\n",
    "            prec_3.append(precision_score(labs2, preds2_temp, pos_label=1))\n",
    "                \n",
    "        if k ==5:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))+(labs[3]/np.log2(4+1))+(labs[4]/np.log2(5+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))+(sorte[3]/np.log2(4+1))+(sorte[4]/np.log2(5+1))\n",
    "            if idcg ==0:\n",
    "                at_5.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_5.append(ndcg)\n",
    "            prec_5.append(precision_score(labs2, preds2_temp, pos_label=1))\n",
    "                \n",
    "        if k ==10:\n",
    "            dcg = (labs[0]/np.log2(1+1))+(labs[1]/np.log2(2+1))+(labs[2]/np.log2(3+1))+(labs[3]/np.log2(4+1))+(labs[4]/np.log2(5+1))+(labs[5]/np.log2(6+1))+(labs[6]/np.log2(7+1))+(labs[7]/np.log2(8+1))+(labs[8]/np.log2(9+1))+(labs[9]/np.log2(10+1))\n",
    "            sorte = sorted(labs2, reverse=True)\n",
    "            idcg = (sorte[0]/np.log2(1+1))+(sorte[1]/np.log2(2+1))+(sorte[2]/np.log2(3+1))+(sorte[3]/np.log2(4+1))+(sorte[4]/np.log2(5+1))+(sorte[5]/np.log2(6+1))+(sorte[6]/np.log2(7+1))+(sorte[7]/np.log2(8+1))+(sorte[8]/np.log2(9+1))+(sorte[9]/np.log2(10+1))\n",
    "            if idcg ==0:\n",
    "                at_10.append(0)\n",
    "            else:\n",
    "                ndcg = dcg/idcg\n",
    "                at_10.append(ndcg)\n",
    "    used_arts.append(art)\n",
    "    \n",
    "print('NDCG scores: at3', s.mean(at_3),'at5', s.mean(at_5),'at10',s.mean(at_10))   \n",
    "print('Precision scores @: at3', s.mean(prec_3), 'at5', s.mean(prec_5))        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
